import pandas as pd
import os
import sys
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError

# Add the parent directory to Python path to import config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config.db_config import DATABASE_URL
except ImportError:
    print("âŒ Database configuration not found. Please check config/db_config.py")
    sys.exit(1)

PROCESSED_DIR = os.path.join("..", "data", "processed")

def create_stock_table(engine, table_name):
    """
    Create a table for stock data if it doesn't exist
    """
    create_table_query = f"""
    CREATE TABLE IF NOT EXISTS {table_name} (
        date DATE PRIMARY KEY,
        close DECIMAL(10, 2),
        high DECIMAL(10, 2),
        low DECIMAL(10, 2),
        open DECIMAL(10, 2),
        volume BIGINT,
        daily_return DECIMAL(8, 6),
        sma_20 DECIMAL(10, 2),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    """
    
    try:
        with engine.connect() as conn:
            conn.execute(text(create_table_query))
            conn.commit()
        print(f"âœ… Table '{table_name}' created/verified successfully")
        return True
    except SQLAlchemyError as e:
        print(f"âŒ Error creating table '{table_name}': {str(e)}")
        return False

def load_stock_data_to_db(ticker="RELIANCE_NS", table_name=None):
    """
    Load processed stock data from CSV to Supabase database
    """
    if table_name is None:
        table_name = f"stock_{ticker.lower()}"
    
    # Check if processed file exists
    csv_file = os.path.join(PROCESSED_DIR, f"{ticker}_processed.csv")
    if not os.path.exists(csv_file):
        print(f"âš ï¸ Processed data file not found: {csv_file}")
        return False
    
    try:
        # Create database engine with IPv4 preference
        engine = create_engine(
            DATABASE_URL,
            connect_args={
                "options": "-c default_transaction_isolation=read_committed",
                "application_name": "stockpulse"
            },
            pool_pre_ping=True,
            pool_recycle=300
        )
        
        # Create table if it doesn't exist
        if not create_stock_table(engine, table_name):
            return False
        
        # Read processed CSV data
        df = pd.read_csv(csv_file, parse_dates=["Date"])
        
        # Clean column names for database (lowercase, underscore)
        df.columns = [col.lower().replace(" ", "_") for col in df.columns]
        
        # Load data to database (replace existing data)
        df.to_sql(
            table_name, 
            engine, 
            if_exists='replace',
            index=False,
            method='multi'
        )
        
        print(f"âœ… Successfully loaded {len(df)} records for {ticker} â†’ table '{table_name}'")
        
        # Show sample of loaded data
        with engine.connect() as conn:
            sample_query = f"SELECT * FROM {table_name} ORDER BY date DESC LIMIT 3"
            result = conn.execute(text(sample_query))
            rows = result.fetchall()
            
            if rows:
                print(f"ğŸ“Š Sample data from '{table_name}':")
                for row in rows:
                    print(f"   {row[0]} | Close: {row[1]} | Volume: {row[5]}")
        
        return True
        
    except SQLAlchemyError as e:
        print(f"âŒ Database error loading {ticker}: {str(e)}")
        return False
    except Exception as e:
        print(f"âŒ Error loading {ticker}: {str(e)}")
        return False

def load_all_stocks():
    """
    Load all processed stock data to database
    """
    # Dynamically find all processed CSV files
    import glob
    
    processed_files = glob.glob(os.path.join(PROCESSED_DIR, "*_processed.csv"))
    stocks = []
    
    for file_path in processed_files:
        filename = os.path.basename(file_path)
        stock_name = filename.replace("_processed.csv", "")
        # Skip analysis files
        if not any(x in stock_name for x in ['analysis_metrics', 'correlation_matrix']):
            stocks.append(stock_name)
    
    success_count = 0
    
    print("ğŸš€ Loading all stock data to Supabase database...")
    print(f"ğŸ“Š Found {len(stocks)} processed stock files")
    
    for stock in stocks:
        print(f"\nğŸ“ˆ Processing {stock}...")
        if load_stock_data_to_db(stock):
            success_count += 1
        else:
            print(f"âŒ Failed to load {stock}")
    
    print(f"\nâœ… Successfully loaded {success_count}/{len(stocks)} stocks to database")
    return success_count == len(stocks)

def test_database_connection():
    """
    Test the database connection
    """
    try:
        engine = create_engine(
            DATABASE_URL,
            connect_args={
                "options": "-c default_transaction_isolation=read_committed",
                "application_name": "stockpulse"
            },
            pool_pre_ping=True,
            pool_recycle=300
        )
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            print("âœ… Database connection successful!")
            return True
    except Exception as e:
        print(f"âŒ Database connection failed: {str(e)}")
        return False

if __name__ == "__main__":
    import sys
    
    print("ğŸ”— Testing database connection...")
    if test_database_connection():
        print("\n" + "="*50)
        
        # Check if specific ticker provided as command line argument
        if len(sys.argv) > 1:
            ticker = sys.argv[1]
            print(f"ğŸš€ Loading {ticker} to database...")
            if load_stock_data_to_db(ticker):
                print("âœ… Successfully loaded to database")
            else:
                print("âŒ Failed to load to database")
        else:
            # Default behavior - load all stocks
            load_all_stocks()
    else:
        print("âŒ Cannot proceed without database connection")
